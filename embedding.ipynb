{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5febed4",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d2c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from speechbrain.inference import EncoderClassifier\n",
    "\n",
    "from voicestudio.datasets import LIBRITTS_P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb9e447",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79087957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "DATASET_ROOT = \"./data\"\n",
    "DATASET_URL = \"train-clean-100\"  # Change to: dev-clean, test-clean, etc.\n",
    "ANNOTATOR = \"df1\"  # Speaker prompt annotator\n",
    "\n",
    "# Model configuration\n",
    "ENCODER_SOURCE = \"speechbrain/spkrec-ecapa-voxceleb\"\n",
    "ENCODER_SAVEDIR = \"tmp/ecapa\"\n",
    "\n",
    "# Processing configuration\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Output configuration\n",
    "OUTPUT_DIR = \"./results/embeddings\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Dataset: {DATASET_URL}\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012fe786",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e826491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LIBRITTS_P(\n",
    "    root=DATASET_ROOT,\n",
    "    url=DATASET_URL,\n",
    "    annotator=ANNOTATOR,\n",
    "    download=True,\n",
    ")\n",
    "print(f\"Dataset size: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b428c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata for style_prompt_key mapping\n",
    "metadata_path = os.path.join(\n",
    "    DATASET_ROOT, \n",
    "    \"metadata_w_style_prompt_tags_v230922.csv\"\n",
    ")\n",
    "\n",
    "print(f\"Loading metadata from: {metadata_path}\")\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "style_key_map = metadata_df.set_index('item_name')['style_prompt_key'].to_dict()\n",
    "\n",
    "print(f\"Loaded {len(style_key_map)} style prompt keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ad5552",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderClassifier.from_hparams(\n",
    "    source=ENCODER_SOURCE,\n",
    "    savedir=ENCODER_SAVEDIR,\n",
    "    run_opts={\"device\": DEVICE}\n",
    ")\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6131a87a",
   "metadata": {},
   "source": [
    "### Dataloader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29379eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"Collate function for DataLoader.\n",
    "    \n",
    "    Returns:\n",
    "        waveforms: List of waveforms (variable length)\n",
    "        metadata: List of metadata dicts\n",
    "    \"\"\"\n",
    "    waveforms = []\n",
    "    metadata_list = []\n",
    "    \n",
    "    for item in batch:\n",
    "        (waveform, sr, orig_text, norm_text, \n",
    "         spk_id, ch_id, utt_id, style_list, speaker_list) = item\n",
    "        \n",
    "        waveforms.append(waveform)\n",
    "        \n",
    "        # Calculate duration properly\n",
    "        # waveform can be [samples] or [1, samples]\n",
    "        num_samples = waveform.shape[-1] if waveform.dim() > 1 else len(waveform)\n",
    "        \n",
    "        metadata_list.append({\n",
    "            'utterance_id': utt_id,\n",
    "            'speaker_id': spk_id,\n",
    "            'chapter_id': ch_id,\n",
    "            'style_prompt_key': style_key_map.get(utt_id, 'unknown'),\n",
    "            'normalized_text': norm_text,\n",
    "            'duration': num_samples / sr,\n",
    "        })\n",
    "    \n",
    "    return waveforms, metadata_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409f316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True if DEVICE == \"cuda\" else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_list = []\n",
    "metadata_records = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (waveforms, metadata_batch) in enumerate(tqdm(dataloader, desc=\"Processing\")):\n",
    "        # Process each waveform in batch\n",
    "        batch_embeddings = []\n",
    "        \n",
    "        for waveform in waveforms:\n",
    "            # Ensure correct shape: [1, samples]\n",
    "            if waveform.dim() == 1:\n",
    "                waveform = waveform.unsqueeze(0)\n",
    "            \n",
    "            # Move to device and extract embedding\n",
    "            waveform = waveform.to(DEVICE)\n",
    "            embedding = encoder.encode_batch(waveform)\n",
    "            \n",
    "            # Extract tensor and move to CPU\n",
    "            embedding = embedding.squeeze().cpu().numpy()\n",
    "            batch_embeddings.append(embedding)\n",
    "        \n",
    "        # Store results\n",
    "        embeddings_list.extend(batch_embeddings)\n",
    "        metadata_records.extend(metadata_batch)\n",
    "        \n",
    "        # Progress update every 10 batches\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            processed = len(embeddings_list)\n",
    "            print(f\"Processed {processed} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633d97ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "embeddings_array = np.stack(embeddings_list)\n",
    "print(f\"\\nEmbeddings shape: {embeddings_array.shape}\")\n",
    "print(f\"Embedding dimension: {embeddings_array.shape[1]}\")\n",
    "\n",
    "# Create metadata DataFrame with specified column order\n",
    "metadata_df = pd.DataFrame(metadata_records, columns=[\n",
    "    'utterance_id',\n",
    "    'speaker_id',\n",
    "    'chapter_id', \n",
    "    'style_prompt_key',\n",
    "    'normalized_text',\n",
    "    'duration',\n",
    "])\n",
    "\n",
    "print(f\"\\nMetadata shape: {metadata_df.shape}\")\n",
    "print(metadata_df.head())\n",
    "\n",
    "print(f\"len(embeddings_list): {len(embeddings_list)}\")\n",
    "print(f\"len(metadata_records): {len(metadata_records)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbacc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_prefix = f\"speaker_embeddings_{DATASET_URL.replace('-', '_')}\"\n",
    "embeddings_path = os.path.join(OUTPUT_DIR, f\"{output_prefix}.npy\")\n",
    "metadata_path = os.path.join(OUTPUT_DIR, f\"{output_prefix}_metadata.csv\")\n",
    "\n",
    "# Save embeddings\n",
    "print(f\"\\nSaving embeddings to: {embeddings_path}\")\n",
    "np.save(embeddings_path, embeddings_array)\n",
    "\n",
    "# Save metadata\n",
    "print(f\"Saving metadata to: {metadata_path}\")\n",
    "metadata_df.to_csv(metadata_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voicestudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
